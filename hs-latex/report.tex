\documentclass[11pt,a4paper, halfparskip]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[bookmarksnumbered,pdftitle={Name}]{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{lmodern}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tabularx}

\usepackage{geometry}
\geometry{a4paper, top=25mm, left=40mm, right=40mm, bottom=30mm,
headsep=10mm, footskip=12mm}

\title{Bericht zum Laborprojekt}
\author{Jeremy Puchta \and Jonathan Lange \and Ali Al-Ali}
\renewcommand*{\titlepagestyle}{empty}

\definecolor{background}{HTML}{FFFFFF}

\lstdefinelanguage{json} {
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
}

\begin{document}

\begin{titlepage}
	\centering
	\includegraphics[width=1\textwidth]{Unilogo}\par\vspace{1cm}
	{\scshape\LARGE Universität Leipzig \par}
	\vspace{0.5cm}
	{\scshape\Large Abteilung Automatische Sprachverarbeitung\par}
	\vspace{0.2cm}
	{\scshape\large Fortgeschrittene Methoden des Information Retrieval\par}
	\vspace{1cm}
	{\huge\bfseries Bericht zum Laborprojekt\par}
	\vspace{1cm}
	{\Large Jeremy Puchta -- Jonathan Lange -- Ali Al-Ali \par}

	\vfill
	
	{\large \today\par}
\end{titlepage}

\newpage

\thispagestyle{empty}
\tableofcontents

\newpage
\pagenumbering{arabic}
\section{Einleitung}

Der vorliegende Bericht erläutert den Aufbau sowie die Funktionsweise der Suchmaschine \textit{Historical News Search}, welche im Rahmen des Laborprojektes innerhalb des Moduls \textit{Fortgeschrittene Methoden des Information Retrieval} im Wintersemester 2018 / 2019 erstellt wurde. 
Ziel des Laborprojektes war es, die vermittelten Vorlesungsinhalte zu vertiefen und diese bei der Erstellung einer domänenspezifischen Suchmaschine umzusetzen. 
Die vorgestellte Suchmaschine dient der Exploration von historischen Nachrichten und Zeitungsartikeln.
Als Anwendungsfälle für eine solche Suchmaschine sind verschiedene Szenarien denkbar. 
Ein Nutzer kann beispielsweise nach der Berichterstattung zu Personen, Gruppen, Orten oder bestimmten historischen Ereignissen suchen.
Eine weitere Möglichkeit der Nutzung stellt die Ahnenforschung dar, bei welcher ein Nutzer in Zeitungsberichten nach Informationen über seine Vorfahren suchen und somit mehr über seine Familienhistorie erfahren kann.

Im folgenden Kapitel wird zunächst der verwendete Technologiestack eingehend beschrieben.
Anschließend erfolgt die Vorstellung des verwendeten Datensatzes und die Analyse dessen mit Methoden der deskriptiven Statistik. 
Die Architektur und der Aufbau der Suchmaschine werden in Kapitel 4 näher dargestellt. 
Dazu zählt insbesondere die Erstellung des Indizes sowie die Umsetzung des Suchprozesses über alle beteiligten Komponenten des Systems.
Kapitel 5 stellt das User Interface sowie die dahinter ablaufenden Prozesse vor.
In Kapitel 6 werden zunächst die Evaluationsmethodik sowie die Resultate der Evaluation erläutert.
Weiterhin wird erklärt, welche Anpassungen vorgenommen wurden, um die Effektivität der Suchmaschine und die Nutzererfahrung zu verbessern.
Abschließend erfolgt in Kapitel 7 eine Zusammenfassung des Projektes und es wird ein Ausblick in Bezug auf eine Weiterentwicklung der Suchmaschine geliefert.

\section{Technologiestack}

Zur Umsetzung des Laborprojektes wird die Open-Source-Suchmaschine \textit{Elasticsearch} verwendet. 
\textit{Elasticsearch} ist in Java geschrieben und basiert auf der Java-Bibliothek \textit{Lucene}. 
Außerdem ist \textit{Elasticsearch} gebaut für den Einsatz auf verteilten Systemen und die Echtzeitverarbeitung von großen Datenmengen, was unter anderem zur Volltextsuche eingesetzt wird und \textit{Elasticsearch} somit zu einer ausgezeichneten Option für die Umsetzung einer Dokumentensuchmaschine macht.
\textit{Elasticsearch} stellt sämtliche Funktionen über eine programmiersprachenunabhängige REST-Schnittstelle zur Verfügung.
Um die Dokumente durchsuchbar zu machen, legt \textit{Elasticsearch} die Datenstruktur des \textit{Invertierten Index} an, in welcher für jeden Term gespeichert wird in welchem Dokument dieser auftritt.

Im Backend des Systems kommt das Python-Framework \textit{Flask} zum Einsatz. 
Bei \textit{Flask} handelt es sich um ein Mikroframework, welches eine einfache, jedoch ebenfalls erweiterbare und robuste Möglichkeit bietet APIs zu erstellen.
Im Frontend wird mit \textit{Angular} ein Framework verwendet, welches Entwickler durch sein Komponentensystem darin unterstützt modularen Quellcode zu produzieren, der sich einfach warten lässt.
Außerdem bringt es bereits viele Funktionen, die häufig im Frontend zum Einsatz kommen mit, wie zum Beispiel Routing. 
Zur Vereinfachung des Deployments und zur Optimierung des Entwicklungsprozesses kommt die Containervirtualisierungs – Technologie \textit{Docker} zum Einsatz.

\section{Datenakquise und -analyse}

Die \textit{Staatsbibliothek zu Berlin} besitzt ein breites Spektrum von historisch bedeutsamen digitalisierten Zeitungen.
Diese werden im hauseigenen Zeitungsinformationssystem namens \textit{ZEFYS} kostenfrei bereitgestellt.
Die Digitalisate, Volltexte und Metadaten der \textit{Berliner Volks-Zeitung (BVZ)} dienen als Korpus für die im Rahmen des Laborprojektes entwickelte Suchmaschine.
Bei der \textit{Berliner Volks-Zeitung} handelt es sich um eine von 1849 bis 1944 veröffentlichte regionale deutsche Tageszeitung aus Berlin.
Sie besitzt große Bedeutung für die Forschung im Bereich der Kulturwissenschaften, da sie im Gegensatz zu den meisten linken Parteizeitungen, über ein gutes Feuilleton verfügt. [QUELLE]
Der Zeitraum der Digitalisate beläuft sich auf die Jahre 1890 bis 1930, wobei einige Jahre stärker abgedeckt sind als andere.
Die Datensets umfassen jeweils strukturierte Metadaten im METS-XML-Containerformat für jede Ausgabe, per OCR erzeugte Volltexte im ALTO-XML-Format mit Wortkoordinaten, binarisierte TIFFs als Grundlage der OCR sowie JPEG2000-Bilder für die Anzeige.
Insgesamt umfasst der Datensatz 103.771 digitalisierte Seiten.

\subsection{Datenverarbeitung}

Mithilfe des ALTO-XML-Formates wird die Möglichkeit geschaffen Digitalisate vollständig und originalgetreu zu replizieren. 
Aus diesem Grund sind neben Zeitungsinhalten Informationen zum Layout der Seite und die exakten Koordinaten der Wörter enthalten.
Dokumente werden von \textit{Elasticsearch} im JSON-Format repräsentiert.
Daher ist es erforderlich die im Datensatz vorhandenen XML-Dateien in das JSON-Format zu konvertieren und dabei relevante Informationen zu extrahieren.
Relevante Informationen stellen beispielsweise das Veröffentlichungsdatum der Zeitung, weitere Informationen wie die Ausgabe und den gesamten Text einer Zeitungsseite dar.
Listing 1 zeigt ein Beispiel für die konvertierte JSON-Repräsentation einer Zeitungsseite.
Interessant ist insbesondere der Schlüssel "Text", der ein dreifach geschachteltes Array bestehend aus den Texten einer Seite enthält.
Innerhalb des Arrays der ersten Ebene befinden sich die einzelnen Artikel einer Seite, welche wiederum Arrays mit den Wörtern der Zeilen eines Artikels enthalten.
Durch diese Repräsentation ist man in der Lage die einzelnen Artikel statt einer gesamten Seite als Ergebnis einer Suchanfrage auszugeben.
Die vollständige Auflösung dieser Scanartefakte stellt eine unverhältnismäßig große Herausforderung dar, weshalb sich gegen die Durchführung der Artefaktsauflösung entschieden wurde. 
Stattdessen erfolgt bei der Auswahl der Referenzmenge für das Repository eine stärkere Einbindung von jüngeren Digitalisaten, wie näher in Kapitel 4.1 beschrieben wird.

\break

\begin{lstlisting}[language=json, firstnumber=1, caption={JSON-Repräsentation einer Zeitungsseite}\label{test123},captionpos=b]
{
  "Year": "1930",
  "Month": "01",
  "Day": "03",
  "NewspaperNumber": "001",
  "PageNumber": "004",
  "Edition": "0",
  "Issue": "059",
  "Text": "[ // Gesamter Zeitungstext
	    [ // Artikel
	     ["Nach","Schluss","der","Redaktion","eingetroffene","Depeschen."], 
	     ["Dortmund,","31.","Maerz.","Wie","die","Rheinisch-Westfaelische"] 
	    ], 
	    [
	     (...)
	    ] 
	   ]"
}
\end{lstlisting}

\subsection{Textstatistiken}
Um ein in sich geschlossenes Projekt im öffentlichen Repository zu präsentieren, wird der gesamte Datensatz auf eine geringere Größe reduziert.
Tabelle 1 zeigt ausgewählte Textstatistiken für diese reduzierte Dokumentkollektion.

\begin{table}[h!]
	\centering
	\begin{tabularx}{0.8\textwidth}{lX}
		\hline
		Gesamtanzahl Dokumente & 6,144\\
		Gesamtanzahl Worte & 44,337,561,540 \\
		Vokabulargröße & 1,663,267 \\
		Wörter mit Vorkommen > 1000 & 1,461,311 \\
		Wörter mit einmaligen Vorkommen & 499 \\
		\hline
	\end{tabularx}
	\caption{Textstatistiken für Dokumentkollektion}
\end{table}

// ALI SCHAUT SICH ZAHLEN NOCHMAL AN! ANSONSTEN BEGRÜNDUNG FÜR VERZERRTE ZAHLEN SCHREIBEN!

\section{Architektur}

In diesem Kapitel werden die Kernprozesse des Systems näher beschrieben. 
Dabei handelt es sich um den Indizierungs- und den Suchprozess.
Abbildung 1 visualisiert die einzelnen Komponenten des Systems mittels UML-Komponentendiagramm. 

// UML-KOMPONENTENDIAGRAMM ARCHITEKTUR DER SUCHMASCHINE 

\subsection{Indizierungsprozess}

Die im Rahmen der Datenvorverarbeitung erstellten JSON-Dokumente werden mit Elasticsearch indiziert. 
Jede Seite einer Zeitung wird dabei als eine JSON-Datei repräsentiert und enthält neben dem Veröffentlichungsdatum und weiteren Metadaten (Ausgabe, Seitenzahl, ...) die Texte der Zeitungsartikel.
Diese stellen den wichtigsten Bestandteil für die Indizierung dar, da in diesem relevante Terme enthalten sind, die von einem Nutzer gesucht werden können.
Wie jedoch bereits in den vorherigen Kapiteln dargelegt wurde, ist die Qualität der Terme durch eine Vielzahl von OCR-Scanartefakten sehr gering.

\subsection{Suchprozess}

\section{Vorstellung der Suchmaschine}

Nachdem die Architektur des Systems in Kapitel 4 erläutert wurde, erfolgt in diesem Kapitel die Vorstellung der Suchmaschine, insbesondere des User Interfaces.
Das User Interface besteht aus drei verschiedenen Sichen, die sich wie folgt darstellen:
	\begin{enumerate}
		\item Landing Page mit Eingabefeld für eine Suchanfrage
		\item Seite zur Auflistung der Suchergebnisse
		\item Seite zur Darstellung von Detailinformationen zu einer Zeitungsseite inklusive des zugehörigen Zeitungsscans  	
	\end{enumerate}
Bei der Beschreibung der Sichten erfolgt eine Erklärung der Prozesse die im System ablaufen.

\subsection{Landing Page}

Bei der \textit{Landing Page} handelt es sich, wie der Name schon sagt, um die Seite, die ein Nutzer sieht sobald dieser die Suchmaschine verwendet.
Auf dieser befindet sich neben einem thematisch passenden und ansprechenden Hintergrundbild ein Eingabefeld, in welcher die Nutzer eine Suchanfragen stellen können. 
Abbildung 1 zeigt die \textit{Landing Page} mit dem Eingabefeld für Suchanfragen.

\begin{figure}[h]
	\includegraphics[width=\linewidth]{images/landing_page.png}
	\caption{Landing Page der Historical News Search}
\end{figure}

\subsection{Auflistung der Suchergebnisse}

Nachdem ein Nutzer seine Suchanfrage in das Eingabefeld auf der \textit{Landing Page} eingegeben hat, wird diese an die \texttt{search}-Methode im Backend übergeben.
Wie bereits in Kapitel 3.2 beschrieben sucht diese in der Dokumentkollektion nach Zeitungsseiten, welche die Terme aus der Suchanfrage enthalten und gibt diese zurück. 
Die zurückgegebenen Zeitungen werden, nach ihrem Gewicht sortiert, in einer Liste von \textit{Cards} dargestellt.
Dabei wird eine Zeitungsseite von je einer \textit{Card} repräsentiert.
Diese enthalten neben einer Überschrift und dem Veröffentlichungsdatum ein kurzes Snippet, um dem Nutzer eine Vorschau auf die Artikel der Zeitungsseite zu bieten und diesen somit bei der Suche nach relevanten Ergebnissen zu unterstützen.
Weiterhin ist zur Gewährleistung der Übersichtlichkeit des User Interfaces eine \textit{Paginierung} implementiert.
Jede Seite enthält besitzt zehn Resultate. 
Abbildung 2 illustriert die Auflistung der Suchergebnisse für eine Suchanfrage nach \texttt{max schmeling}.

// ABBILDUNG EINFÜGEN!

\subsection{Detailansicht}

Klickt ein Nutzer auf eine der \textit{Cards} aus der Ergebnisliste, werden ihm sämtliche Artikel angezeigt, die auf der entsprechenden Zeitungsseite stehen.

// WIRD NACH UMBAU DER DETAILANSICHT FORTGEFÜHRT

// ABBILDUNG EINFÜGEN SOBALD FERTIGGESTELLT

\section{Evaluation}

\section{Zusammenfassung und Ausblick}

% ----------------------------------------------------------------------------

\newpage
\begin{footnotesize}

% IF YOU DO NOT USE BIBTEX, USE THE FOLLOWING SAMPLE SCHEME FOR THE REFERENCES
% ----------------------------------------------------------------------------

\begin{thebibliography}{99}

% For articles
%\bibitem{1}David Caswell, Konstantin Dörr, "Automated Journalism 2.0: Event-driven naratives", \emph{Journalism Practice}, 09.05.2017.

%\bibitem{2}Andreas Graefe, "Guide to Automated Journalism", \emph{Columbia University Academic Commons}, 07.01.2016.

%\bibitem{3}L. Leppänen, M. Munezero, M. Granroth-Wilding, H. Toivonen, "Data-Driven News Generation for Automated Journalism", \emph{University of Helsinki}, 2017

%\bibitem{4}Retresco GmbH, ``Retresco - Textgenerierung'', \emph{\\https://www.retresco.de/textgenerierung/}, zuletzt abgerufen 01.07.2018

%\bibitem{5}DFL Deutsche Fußball Liga GmbH, ``Schalke 04 krönt Saison mit Heimsieg - Eintracht Frankfurt verpasst vorerst Europa'', \emph{https://www.bundesliga.com/de/bundesliga/news/fc-schalke-04-eintracht-frankfurt-34-spieltag-spielbericht.jsp}, zuletzt abgerufen 01.07.2018

%\bibitem{6}Statistik zum Spiel FC Bayern München - Vfb Stuttgart auf Bundesliga.de, \\
%\emph{https://www.bundesliga.com/de/bundesliga/spieltag/2017-2018/34-fc\_bayern\_muenchen-vfb\_stuttgart.jsp?statistics}, zuletzt abgerufen 24.08.2018

\end{thebibliography}
%
%\section{Abbildungsverzeichnis}
%


% IF YOU USE BIBTEX,
% - DELETE THE TEXT BETWEEN THE TWO ABOVE DASHED LINES
% - UNCOMMENT THE NEXT TWO LINES AND REPLACE 'Name_Of_Your_BibFile'

%\bibliographystyle{unsrt}
%\bibliography{Name_Of_Your_BibFile}

\end{footnotesize}

\end{document}